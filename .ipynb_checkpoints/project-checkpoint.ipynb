{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('./Dataset/data.csv')\n",
    "\n",
    "# Here's how you reduce sample the data set. sample_data will contain every 100th row. This is just as an example\n",
    "# Should use more than a 100th of the data\n",
    "sample_data = data.iloc[::100, :]\n",
    "sample_data.head()\n",
    "\n",
    "# Splitting the data into features and song profiles\n",
    "song_profiles = sample_data[['id', 'name', 'artists', 'release_date', 'year', 'id']].copy()\n",
    "features = sample_data.drop('name', axis=1).copy().drop('artists', axis=1).drop('id', axis=1).drop('release_date', axis=1).values.tolist()\n",
    "# Drop irrelevant columns in feature set\n",
    "# features = features.drop('key', axis=1)\n",
    "    # Key?\n",
    "    # My guess is that the key is the western music scale key that the song is in\n",
    "    # possibly normalized for major scales? (e.g., gmaj == cmin)\n",
    "# sample_data\n",
    "# song_profiles.head()\n",
    "# features.head()\n",
    "\n",
    "# I'm going to make this an RNN. Deal.\n",
    "# we can use the index of the song in the features list as the class. Because we're "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import copy\n",
    "# We define a our recurrent neural network as one where the features of the current song being played is the input, along \n",
    "# along with classifiers (i.e., their place in the features array) as other inputs.\n",
    "# we return the value as a binary number representation of the index\n",
    "\n",
    "def GetClassFromNum(num):\n",
    "    out = [0 for _ in range(20)] #we have 600k songs as our input, thus we need 20 bits to hold the each as a given class.\n",
    "    i = 0\n",
    "    while(num > 0):\n",
    "        out[i] = num % 2\n",
    "        num = num // 2\n",
    "    return out\n",
    "\n",
    "def GetNumFromClass(vals):\n",
    "    out = 0\n",
    "    for i in range(len(vals)):\n",
    "        out += (i**2)*vals[i]\n",
    "    return out\n",
    "\n",
    "class Neuron:\n",
    "    Weights = []\n",
    "    Output = 1.0\n",
    "    Delta = 0.5\n",
    "    \n",
    "    def __init__(self, prevLayerWidth):\n",
    "        self.Weights = [random.random() for _ in range(prevLayerWidth + 1)]\n",
    "    \n",
    "    def Activate(self, inputs):\n",
    "        activation_val = self.Weights[-1]\n",
    "        for i in range(len(inputs)):\n",
    "            activation_val += inputs[i] * self.Weights[i]\n",
    "        self.Output = max(0, activation_val)\n",
    "        return self.Output\n",
    "    \n",
    "    def UpdateWeights(self, regressive_outputs, learnRate):\n",
    "        for i in range(len(regressive_outputs)):\n",
    "            self.Weights[i] += learn_rate * self.Delta * regressive_outputs[i]\n",
    "        self.Weights[-1] += learn_rate * self.Delta\n",
    "    \n",
    "    def UpdateDelta(self, error):\n",
    "        self.Delta = error * (0 if self.Output < 0 else 1)\n",
    "\n",
    "class RecurrentNeuralNetwork:\n",
    "    RecurrentInputs = 0\n",
    "    OutputLength = 0\n",
    "    NeuronLayers = []\n",
    "    LearningRate = 0.0\n",
    "    \n",
    "    def __init__(self, features, recurrent_inputs, hidden_layers, output_length, learning_rate):\n",
    "        print(\"Building neural network with\", features, \" features, \", recurrent_inputs, \" recurrent inputs, and \", hidden_layers, \"hidden layers.\")\n",
    "        self.RecurrentInputs = recurrent_inputs\n",
    "        self.LearningRate = learning_rate\n",
    "        self.OutputLength = output_length\n",
    "        \n",
    "        y_intercept = features + recurrent_inputs * 20 #each recurrent inputs has 20 values\n",
    "        prev_width = y_intercept\n",
    "        slope = (output_length - y_intercept)/hidden_layers #for quicker learning, we narrow the scope of each layer a bit\n",
    "        \n",
    "        for i in range(hidden_layers + 1):\n",
    "            next_len = math.ceil((i + 1)*slope + y_intercept) if i < hidden_layers - 1 else output_length\n",
    "            for j in range(next_len):\n",
    "                self.NeuronLayers.append([Neuron(prev_width)])\n",
    "            prev_width = next_len\n",
    "    \n",
    "    def ForwardPropagation(self, current_input, recurrent_inputs):\n",
    "        # setup previous layers \"output\" as the total input\n",
    "        layer_output = current_input\n",
    "        for recurrent_input in recurrent_inputs:\n",
    "            for val in recurrent_input:\n",
    "                layer_output.append(val)\n",
    "        \n",
    "        for layer in self.NeuronLayers:\n",
    "            next_layer_input = []\n",
    "            for neuron in layer:\n",
    "                next_layer_input.append(neuron.Activate(layer_output))\n",
    "            layer_output = next_layer_input\n",
    "        return layer_output\n",
    "    \n",
    "    def BackwardPropagation(self, expected_value):\n",
    "        prev_layer = []\n",
    "        for layer in reversed(self.NeuronLayers):\n",
    "            layer_error = []\n",
    "            if (layer is self.NeuronLayers[-1]):\n",
    "                for i in range(len(layer)):\n",
    "                    layer_error.append(expected_value[i] - layer[i].Output)\n",
    "            else:\n",
    "                for i in range(len(layer)):\n",
    "                    error = 0.0\n",
    "                    for neuron in prev_layer:\n",
    "                        error += neuron.Weights[i] * neuron.Delta\n",
    "                    layer_error.append(error)\n",
    "            for i in range(len(layer)):\n",
    "                layer[i].UpdateDelta(layer_error[i])\n",
    "            prev_layer = layer\n",
    "\n",
    "    def UpdateAllWeights(self, current_input, recurrent_inputs):\n",
    "        layer_input = current_input\n",
    "        for recurrent_input in recurrent_inputs:\n",
    "            for val in recurrent_input:\n",
    "                layer_input.append(val)\n",
    "        \n",
    "        for layer in self.NeuronLayers:\n",
    "            next_layer_input = []\n",
    "            for neuron in layer:\n",
    "                neuron.UpdateWeights(layer_input, self.LearningRate)\n",
    "                next_layer_input.append(neuron.Output)\n",
    "            layer_input = next_inputs\n",
    "\n",
    "    def SimilarityCalculation(self, input_class, output_class):\n",
    "        numer = 0\n",
    "        denom = 0\n",
    "        print(\"similarity sanity check:\", len(input_class), \"\\t\", len(output_class))\n",
    "        for i in range(len(input_class)):\n",
    "            numer += (input_class[i]*output_class[i])\n",
    "            denom *= ((input_class[i]**2) + (output_class[i]**2))**0.5\n",
    "        return numer/denom\n",
    "    \n",
    "    def Train(self, training_set, epochs):\n",
    "        shuffled_set = copy.copy(training_set)\n",
    "        print(\"RNN starting training with\", epochs, \"epochs and \", self.RecurrentInputs, \" recurrent inputs. \")\n",
    "        prev_inputs = []\n",
    "        expected_similarity = 0.75\n",
    "\n",
    "        for i in range(self.RecurrentInputs):\n",
    "            prev_inputs.append([0 for _ in range(self.OutputLength)])\n",
    "        \n",
    "        for epoch in range(epochs + 1):\n",
    "            total_epoch_error = 0.0\n",
    "            random.shuffle(shuffled_set)\n",
    "            for value in shuffled_set:\n",
    "                possible_output = self.ForwardPropagation(value, prev_inputs)\n",
    "                calc_possible_output = []\n",
    "                for el in possible_output:\n",
    "                    calc_possible_output.append(1 if el > 0.5 else 0)\n",
    "\n",
    "                similarity = 0\n",
    "                print(\"\\tInput:\", value)\n",
    "                print(\"\\t\\tDirect Output:\", possible_output, \"\\tCalculated Output: \", calc_possible_output)\n",
    "                classnum = GetNumFromClass(calc_possible_output)\n",
    "                print(\"\\t\\tClass Number\", classnum)\n",
    "                if (classnum < len(training_set)):\n",
    "                    features = training_set[classnum]\n",
    "                    print(\"\\t\\tFeatures:\", features)\n",
    "                    similarity = self.SimilarityCalculation(value, features)\n",
    "                expected = []\n",
    "                \n",
    "                print(\"\\t\\tSimilarity:\", similarity)\n",
    "                \n",
    "                if (similarity >= expected_similarity and\n",
    "                    possible_output not in prev_inputs):\n",
    "                    next_recurrent_inputs = (prev_inputs[1:]).append(possible_output)\n",
    "                    expected = calc_possible_output\n",
    "                elif (similarity < expected_similarity):\n",
    "                    for el in possible_output:\n",
    "                        expected.append(el * similarity)\n",
    "                self.BackwardPropagation(expected)\n",
    "                self.UpdateWeights(value, prev_inputs)\n",
    "                prev_inputs = next_recurrent_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building neural network with 15  features,  20  recurrent inputs, and  30 hidden layers.\n"
     ]
    }
   ],
   "source": [
    "new_network = RecurrentNeuralNetwork(len(features[0]), 20, 30, 20, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN starting training with 20 epochs and  20  recurrent inputs. \n",
      "\tInput: [0.733, 0.631, 291697.0, 0.207, 0.0, 0.0, 11.0, 0.254, -19.485, 0.0, 0.0, 0.96, 82.71, 0.51, 1935.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\t\tDirect Output: [1.2299169875186635] \tCalculated Output:  [1]\n",
      "\t\tClass Number 0\n",
      "\t\tFeatures: [0.926, 0.742, 184070.0, 0.243, 0.0, 0.0, 10.0, 0.0873, -11.013, 1.0, 12.0, 0.105, 73.438, 0.773, 1942.0]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-d5a2e6a8e879>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_network\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-107-f7b79431ee46>\u001b[0m in \u001b[0;36mTrain\u001b[1;34m(self, training_set, epochs)\u001b[0m\n\u001b[0;32m    143\u001b[0m                     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclassnum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\t\\tFeatures:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                     \u001b[0msimilarity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSimilarityCalculation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m                 \u001b[0mexpected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-107-f7b79431ee46>\u001b[0m in \u001b[0;36mSimilarityCalculation\u001b[1;34m(self, input_class, output_class)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[0mnumer\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput_class\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0moutput_class\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_class\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0moutput_class\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnumer\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdenom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "new_network.Train(features, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
