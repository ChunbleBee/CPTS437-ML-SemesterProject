{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('./Dataset/data.csv')\n",
    "\n",
    "# Here's how you reduce sample the data set. sample_data will contain every 100th row. This is just as an example\n",
    "# Should use more than a 100th of the data\n",
    "sample_data = data.iloc[::100, :]\n",
    "sample_data.head()\n",
    "\n",
    "# Splitting the data into features and song profiles\n",
    "song_profiles = sample_data[['id', 'name', 'artists', 'release_date', 'year', 'id']].copy()\n",
    "features = sample_data.drop('name', axis=1).copy().drop('artists', axis=1).drop('id', axis=1).drop('release_date', axis=1).values.tolist()\n",
    "# Drop irrelevant columns in feature set\n",
    "# features = features.drop('key', axis=1)\n",
    "    # Key?\n",
    "    # My guess is that the key is the western music scale key that the song is in\n",
    "    # possibly normalized for major scales? (e.g., gmaj == cmin)\n",
    "# sample_data\n",
    "# song_profiles.head()\n",
    "# features.head()\n",
    "\n",
    "# I'm going to make this an RNN. Deal.\n",
    "# we can use the index of the song in the features list as the class. Because we're "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import copy\n",
    "# We define a our recurrent neural network as one where the features of the current song being played is the input, along \n",
    "# along with classifiers (i.e., their place in the features array) as other inputs.\n",
    "# we return the value as a binary number representation of the index\n",
    "\n",
    "def GetClassFromNum(num):\n",
    "    out = [0 for _ in range(20)] #we have 600k songs as our input, thus we need 20 bits to hold any as a \n",
    "    i = 0\n",
    "    while(num > 0):\n",
    "        out[i] = num % 2\n",
    "        num = num // 2\n",
    "        i += 1\n",
    "    print(out)\n",
    "    return out\n",
    "\n",
    "def GetNumFromClass(vals):\n",
    "    out = 0\n",
    "    for i in range(len(vals)):\n",
    "        out += (i**2)*vals[i]\n",
    "    return out\n",
    "\n",
    "class Neuron:\n",
    "    Weights = []\n",
    "    Output = 1.0\n",
    "    Delta = 0.5\n",
    "    \n",
    "    def __init__(self, prevLayerWidth):\n",
    "        self.Weights = [random.random() for _ in range(prevLayerWidth + 1)]\n",
    "    \n",
    "    def Activate(self, inputs):\n",
    "        activation_val = self.Weights[-1]\n",
    "        for i in range(len(inputs)):\n",
    "            activation_val += inputs[i] * self.Weights[i]\n",
    "        self.Output = np.tanh(activation_val)\n",
    "        return self.Output\n",
    "    \n",
    "    def UpdateWeights(self, regressive_outputs, learn_rate):\n",
    "        for i in range(len(regressive_outputs)):\n",
    "            self.Weights[i] += learn_rate * self.Delta * regressive_outputs[i]\n",
    "        self.Weights[-1] += learn_rate * self.Delta\n",
    "    \n",
    "    def UpdateDelta(self, error):\n",
    "        self.Delta = error * (1 - np.tanh(self.Output)**2)\n",
    "\n",
    "class RecurrentNeuralNetwork:\n",
    "    RecurrentInputs = 0\n",
    "    OutputLength = 0\n",
    "    NeuronLayers = []\n",
    "    LearningRate = 0.0\n",
    "    \n",
    "    def __init__(self, features, recurrent_inputs, hidden_layers, output_length, learning_rate):\n",
    "        print(\"Building neural network with\", features, \"features,\", recurrent_inputs, \"recurrent inputs, and\", hidden_layers, \"hidden layers.\")\n",
    "        self.RecurrentInputs = recurrent_inputs\n",
    "        self.LearningRate = learning_rate\n",
    "        self.OutputLength = output_length\n",
    "        \n",
    "        y_intercept = (features + recurrent_inputs*output_length)\n",
    "        slope = (output_length - y_intercept)/hidden_layers #for quicker learning, we narrow the scope of each layer a bit\n",
    "        prev_width = y_intercept\n",
    "        for i in range(hidden_layers + 1):\n",
    "            print(\"\\tBuilding layer\", i, \"with neurons\", prev_width)\n",
    "            next_len = math.ceil(i*slope + y_intercept) if (i < hidden_layers) else output_length\n",
    "            for j in range(next_len):\n",
    "                self.NeuronLayers.append([Neuron(prev_width) for _ in range(prev_width)])\n",
    "            prev_width = next_len\n",
    "        print(\"Completed!\")\n",
    "    \n",
    "    def ForwardPropagation(self, current_input, recurrent_inputs):\n",
    "        # setup previous layers \"output\" as the total input\n",
    "        layer_output = copy.deepcopy(current_input)\n",
    "        for recurrent_input in recurrent_inputs:\n",
    "            for val in recurrent_input:\n",
    "                layer_output.append(val)\n",
    "        \n",
    "        for layer in self.NeuronLayers:\n",
    "            next_layer_input = []\n",
    "            for neuron in layer:\n",
    "                next_layer_input(neuron.Activate(layer_output))\n",
    "            layer_output = next_layer_input\n",
    "        return layer_output\n",
    "    \n",
    "    def BackwardPropagation(self, expected_value):\n",
    "        prev_layer = []\n",
    "        for layer in reversed(self.NeuronLayers):\n",
    "            layer_error = []\n",
    "            if (layer is self.NeuronLayers[-1]):\n",
    "                for i in range(len(layer)):\n",
    "                    layer_error.append(expected_value[i] - layer[i].Output)\n",
    "            else:\n",
    "                for i in range(len(layer)):\n",
    "                    error = 0.0\n",
    "                    for neuron in prev_layer:\n",
    "                        error += neuron.Weights[i] * neuron.Delta\n",
    "                    layer_error.append(error)\n",
    "            for i in range(len(layer)):\n",
    "                layer[i].UpdateDelta(layer_error[i])\n",
    "            prev_layer = layer\n",
    "\n",
    "    def UpdateAllWeights(self, current_input, recurrent_inputs):\n",
    "        layer_input = current_input\n",
    "        for recurrent_input in recurrent_inputs:\n",
    "            for val in recurrent_input:\n",
    "                layer_input.append(val)\n",
    "        \n",
    "        for layer in self.NeuronLayers:\n",
    "            next_layer_input = []\n",
    "            for neuron in layer:\n",
    "                neuron.UpdateWeights(layer_input, self.LearningRate)\n",
    "                next_layer_input.append(neuron.Output)\n",
    "            layer_input = next_layer_input\n",
    "\n",
    "    def SimilarityCalculation(self, input_class, output_class):\n",
    "        numer = 0\n",
    "        denom = 0\n",
    "        for i in range(len(input_class)):\n",
    "            numer += (input_class[i]*output_class[i])\n",
    "            denom *= ((input_class[i]**2) + (output_class[i]**2))**0.5\n",
    "        if (denom != 0):\n",
    "            return numer/denom\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def Train(self, training_set, epochs):\n",
    "        shuffled_set = copy.copy(training_set)\n",
    "        print(\"RNN starting training with\", epochs, \"epochs and \", self.RecurrentInputs, \" recurrent inputs. \")\n",
    "        prev_inputs = []\n",
    "        expected_similarity = 0.75\n",
    "        blank = [0 for _ in range(self.OutputLength)]\n",
    "\n",
    "        for i in range(self.RecurrentInputs):\n",
    "            prev_inputs.append([0 for _ in range(self.OutputLength)])\n",
    "        \n",
    "        for epoch in range(epochs + 1):\n",
    "            total_epoch_error = 0.0\n",
    "            random.shuffle(shuffled_set)\n",
    "            for value in shuffled_set:\n",
    "                possible_output = self.ForwardPropagation(value, prev_inputs)\n",
    "                calc_possible_output = []\n",
    "                for el in possible_output:\n",
    "                    calc_possible_output.append(1 if el > 0 else 0)\n",
    "\n",
    "                similarity = 0\n",
    "                print(\"\\tInput:\", value)\n",
    "                print(\"\\t\\tDirect Output:\", possible_output, \"\\tCalculated Output: \", calc_possible_output)\n",
    "                classnum = GetNumFromClass(calc_possible_output)\n",
    "                print(\"\\t\\tClass Number\", classnum)\n",
    "                if (classnum < len(training_set)):\n",
    "                    features = training_set[classnum]\n",
    "                    print(\"\\t\\tFeatures:\", features)\n",
    "                    similarity = self.SimilarityCalculation(value, features)\n",
    "                expected = []\n",
    "                \n",
    "                print(\"\\t\\tSimilarity:\", similarity)\n",
    "                next_recurrent_inputs = prev_inputs\n",
    "                \n",
    "                if (similarity >= expected_similarity and\n",
    "                    possible_output not in prev_inputs):\n",
    "                    next_recurrent_inputs = (prev_inputs[1:]).append(possible_output)\n",
    "                    expected = calc_possible_output\n",
    "                elif (similarity < expected_similarity):\n",
    "                    for el in possible_output:\n",
    "                        expected.append(el * similarity)\n",
    "                self.BackwardPropagation(expected)\n",
    "                self.UpdateAllWeights(value, prev_inputs)\n",
    "                prev_inputs = next_recurrent_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building neural network with 15 features, 20 recurrent inputs, and 30 hidden layers.\n",
      "\tBuilding layer 0 with neurons 415\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-175-c97f1c473062>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_network\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRecurrentNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-174-754f19535f03>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, features, recurrent_inputs, hidden_layers, output_length, learning_rate)\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mnext_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mslope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my_intercept\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mhidden_layers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0moutput_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNeuronLayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mNeuron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_width\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[0mprev_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Completed!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-174-754f19535f03>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mnext_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mslope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my_intercept\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mhidden_layers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0moutput_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNeuronLayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mNeuron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_width\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[0mprev_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Completed!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-174-754f19535f03>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, prevLayerWidth)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevLayerWidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWeights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprevLayerWidth\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mActivate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-174-754f19535f03>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevLayerWidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWeights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprevLayerWidth\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mActivate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_network = RecurrentNeuralNetwork(len(features[0]), 20, 30, 20, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN starting training with 20 epochs and  20  recurrent inputs. \n",
      "\tInput: [0.0555, 0.263, 284496.0, 0.759, 0.0, 0.0, 0.0, 0.231, -7.2879999999999985, 1.0, 57.0, 0.0431, 179.90400000000002, 0.429, 1987.0]\n",
      "\t\tDirect Output: [0.4842812478978636] \tCalculated Output:  [0]\n",
      "\t\tClass Number 0\n",
      "\t\tFeatures: [0.926, 0.742, 184070.0, 0.243, 0.0, 0.0, 10.0, 0.0873, -11.013, 1.0, 12.0, 0.105, 73.438, 0.773, 1942.0]\n",
      "\t\tSimilarity: 0\n",
      "\tInput: [0.628, 0.772, 164653.0, 0.7290000000000001, 0.0, 0.0169, 4.0, 0.0959, -7.934, 1.0, 44.0, 0.114, 146.537, 0.867, 1992.0]\n",
      "\t\tDirect Output: [0.2739576579137026] \tCalculated Output:  [0]\n",
      "\t\tClass Number 0\n",
      "\t\tFeatures: [0.926, 0.742, 184070.0, 0.243, 0.0, 0.0, 10.0, 0.0873, -11.013, 1.0, 12.0, 0.105, 73.438, 0.773, 1942.0]\n",
      "\t\tSimilarity: 0\n",
      "\tInput: [0.418, 0.598, 288261.0, 0.402, 0.0, 0.3229999999999999, 11.0, 0.125, -14.019, 1.0, 1.0, 0.059, 95.018, 0.225, 2011.0]\n",
      "\t\tDirect Output: [0.12764188421795222] \tCalculated Output:  [0]\n",
      "\t\tClass Number 0\n",
      "\t\tFeatures: [0.926, 0.742, 184070.0, 0.243, 0.0, 0.0, 10.0, 0.0873, -11.013, 1.0, 12.0, 0.105, 73.438, 0.773, 1942.0]\n",
      "\t\tSimilarity: 0\n",
      "\tInput: [0.872, 0.6409999999999999, 340333.0, 0.0366, 0.0, 0.155, 0.0, 0.107, -26.04, 1.0, 11.0, 0.0428, 102.778, 0.196, 1963.0]\n",
      "\t\tDirect Output: [0.05506698099513733] \tCalculated Output:  [0]\n",
      "\t\tClass Number 0\n",
      "\t\tFeatures: [0.926, 0.742, 184070.0, 0.243, 0.0, 0.0, 10.0, 0.0873, -11.013, 1.0, 12.0, 0.105, 73.438, 0.773, 1942.0]\n",
      "\t\tSimilarity: 0\n",
      "\tInput: [0.894, 0.524, 253133.0, 0.316, 0.0, 0.711, 7.0, 0.157, -19.321, 0.0, 34.0, 0.0399, 92.605, 0.7859999999999999, 1990.0]\n",
      "\t\tDirect Output: [0.023472730872412154] \tCalculated Output:  [0]\n",
      "\t\tClass Number 0\n",
      "\t\tFeatures: [0.926, 0.742, 184070.0, 0.243, 0.0, 0.0, 10.0, 0.0873, -11.013, 1.0, 12.0, 0.105, 73.438, 0.773, 1942.0]\n",
      "\t\tSimilarity: 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-153-d5a2e6a8e879>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_network\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-151-74e5e114cf38>\u001b[0m in \u001b[0;36mTrain\u001b[1;34m(self, training_set, epochs)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshuffled_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mshuffled_set\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                 \u001b[0mpossible_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mForwardPropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m                 \u001b[0mcalc_possible_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossible_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-151-74e5e114cf38>\u001b[0m in \u001b[0;36mForwardPropagation\u001b[1;34m(self, current_input, recurrent_inputs)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mnext_layer_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mneuron\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                 \u001b[0mnext_layer_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneuron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mActivate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_layer_input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-151-74e5e114cf38>\u001b[0m in \u001b[0;36mActivate\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mactivation_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWeights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mactivation_val\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWeights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivation_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "new_network.Train(features, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
